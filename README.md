# AI Assurance Testing 
## 1. Model Card: 
Name: 
Purpose: 
Architecture:
Input and output structure: 
Data sources:
Training methodology:
Known limitations:
Potential biases:
Performance boundaries: (based on the data used during development). 

## 2. Audit Card: (is the primary document used to define, manage, and record the assurance of an AI-enabled system).
 (a) Scope of evaluation:
 (b) System under test
 (c) Execution and consolidation 
Purpose
Configuration
Boundaries
Dimensions evaluated
Results Obtained from corresponding Test Cards
Risks
Findings
Recommendations

## 3. Test Card  (designed to ensure that every test is executed in a structured, transparent, and reproducible manner.)
 Once a test is completed, the Test Card becomes the formal record of that activity, serving as the source of evidence for audit and review
 Methodology
 Execution
 Test Results
 Dimension Tested (Tests Only 1 assurance dimension: (e.g. fairness, robustness, safety, security, or performance))
 Records how that aspect of the system was evaluated. 
 Test objective 
 Rationale
 Datasets
 Environments
 Tools
 Metrics and thresholds applied
 Outcomes observed

## File Formats: 
MOD-YYYY-NNNN
AUD-YYYY-NNNN
TEST-YYYY-NNNN


## Categories/Dimension
1. Safety
2. Robustness & Resilience
3. Fairness / Non-discrimination
4. Explainability / Interpretability
5. Accountability
6. Privacy & Data Governance
7. Human Agency & Oversight
8. Transparency/Verifiability
9. Security
10. Inclusiveness & Accessibility
11. Contestability / Redress
12. Environmental & Societal Wellbeing
13. Performance


